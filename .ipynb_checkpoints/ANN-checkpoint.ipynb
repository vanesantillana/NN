{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as mpl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(z):\n",
    "    ### START CODE HERE ### (≈ 1 line of code)\n",
    "    s = 1 / (1 + np.exp(-z))\n",
    "    ### END CODE HERE ###\n",
    "    \n",
    "    return s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_X = np.loadtxt('xy/x.csv', delimiter=',')\n",
    "train_Y = np.loadtxt('xy/y.csv', delimiter=',')\n",
    "theta_1 = np.loadtxt('theta/theta1.csv', delimiter=',')\n",
    "theta_2 = np.loadtxt('theta/theta2.csv', delimiter=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GRADED FUNCTION: initialize_parameters\n",
    "\n",
    "def initialize_parameters(n_x, n_h, n_y):\n",
    "    \n",
    "    np.random.seed(2) # Recordemos que los pesos /tetha/W se inicializan en random\n",
    "    \n",
    "    W1 = np.random.randn(n_h, n_x) * 0.01\n",
    "    W2 = np.random.randn(n_y, n_h ) * 0.01\n",
    "    #W1 = theta_1\n",
    "    #W2 = theta_2\n",
    "\n",
    "\n",
    "    #assert (W1.shape == (n_h, n_x))\n",
    "    #assert (W2.shape == (n_y, n_h ))\n",
    "    \n",
    "    parameters = {\"W1\": W1,                  \n",
    "                  \"W2\": W2}\n",
    "    return parameters\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Forward\n",
    "def forward(X,parameters):\n",
    "    \n",
    "    W1 = parameters[\"W1\"]\n",
    "    W2 = parameters[\"W2\"]\n",
    "    \n",
    "    m = X.shape[0]\n",
    "    A1 = np.c_[np.ones((m,1)),X] #Añadimos el bías (5000,401)\n",
    "    Z2 = np.dot(A1, W1.T)#(5000,401) * (401,25) = (5000,25)\n",
    "    A2 = sigmoid(Z2)# (5000,25)\n",
    "    #A2 = np.c_[np.ones((Z2.shape[0],1)),A2] #Añadiendo una columna (5000,26)\n",
    "    Z3 = np.dot(A2,W2.T) #(5000,26) * (26,10) = 5000,10)\n",
    "    A3 = sigmoid(Z3)#(5000,10) --nuestra predicción\n",
    "    \n",
    "    cache = {\"A1\": A1,\n",
    "             \"Z2\": Z2,\n",
    "             \"A2\": A2,\n",
    "             \"Z3\": Z3,\n",
    "             \"A3\": A3}\n",
    "    \n",
    "    return A3,cache"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Calculamos el Costo\n",
    "\n",
    "def compute_cost(A3, Y):\n",
    "    m = Y.shape[0] #(5000,10)\n",
    "    cost = (- 1 / m) * np.sum(np.sum(Y * np.log(A3) + (1 - Y) * (np.log(1 - A3)), axis=1), axis=0)\n",
    "    return cost\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoidGradient(z):\n",
    "    gz = sigmoid(z)\n",
    "    return gz * (1-gz);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Cálculo de la Gradiente\n",
    "#Esta funcion retornará el costo y el gradiente\n",
    "def compute_gradient_reg(cache,parameters, X, yNew):\n",
    "    \n",
    "    W1 = parameters[\"W1\"]\n",
    "    W2 = parameters[\"W2\"]\n",
    "    \n",
    "    a1 = cache[\"A1\"] #(5000,401)\n",
    "    z2 = cache[\"Z2\"] #(5000,21)\n",
    "    a2 = cache[\"A2\"] #(5000,26)\n",
    "    z3 = cache[\"Z3\"] #(5000,10)\n",
    "    a3 = cache[\"A3\"] #(5000,10)\n",
    "    \n",
    "    m = X.shape[0]\n",
    "    \n",
    "    d3 = a3 - yNew #(5000,10)\n",
    "    #d2 = np.dot(d3,W2) * sigmoidGradient(np.c_[np.ones((z2.shape[0],1)),z2])#sigmoide again\n",
    "    d2 = np.dot(d3,W2) * sigmoidGradient(z2)#sigmoide again\n",
    "    #print(\"d2: \", d2[0][0])\n",
    "    #d2 = d2[:,1:]  #(5000,25)\n",
    "    \n",
    "    delta1 = np.dot(d2.T,a1) #(25,5000).(5000,401) = (25,401)\n",
    "    delta2 = np.dot(d3.T,a2) #(10,5000).(5000,26) = (10,26)\n",
    "    \n",
    "    grad1 = delta1/m\n",
    "    grad2 = delta2/m\n",
    "    \n",
    "    grad = {\"grad1\": grad1,\n",
    "            \"grad2\": grad2,\n",
    "           }\n",
    "    \n",
    "    return grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GRADED FUNCTION: update_parameters\n",
    "\n",
    "def update_parameters(parameters, grads, learning_rate=1.5):\n",
    "    W1 = parameters[\"W1\"]\n",
    "    W2 = parameters[\"W2\"]\n",
    "    \n",
    "   \n",
    "    dW1 = grads[\"grad1\"]\n",
    "    dW2 = grads[\"grad2\"]\n",
    "\n",
    "\n",
    "    W1 = W1 - learning_rate * dW1\n",
    "    W2 = W2 - learning_rate * dW2\n",
    "    ### END CODE HERE ###\n",
    "    \n",
    "    parameters = {\"W1\": W1,\n",
    "                  \"W2\": W2}\n",
    "    \n",
    "    return parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GRADED FUNCTION: nn_model\n",
    "\n",
    "def nn_model(X, Y, n_h, num_iterations=2000):\n",
    "\n",
    "    np.random.seed(3)\n",
    "    n_x = X.shape[1]+1\n",
    "    n_y = Y.shape[1] \n",
    "    \n",
    "    # Initialize parameters, then retrieve W1, b1, W2, b2. Inputs: \"n_x, n_h, n_y\". Outputs = \"W1, b1, W2, b2, parameters\".\n",
    "    parameters = initialize_parameters(n_x, n_h, n_y)\n",
    "    \n",
    "    for i in range(0, num_iterations):\n",
    "         \n",
    "        # Forward propagation. Inputs: \"X, parameters\". Outputs: \"A2, cache\".\n",
    "        A3, cache = forward(X, parameters)\n",
    "        \n",
    "        # Cost function. Inputs: \"A2, Y, parameters\". Outputs: \"cost\".\n",
    "        cost = compute_cost(A3, Y)\n",
    " \n",
    "        # Backpropagation. Inputs: \"parameters, cache, X, Y\". Outputs: \"grads\".\n",
    "        grads = compute_gradient_reg(cache, parameters, X, Y)\n",
    " \n",
    "        # Gradient descent parameter update. Inputs: \"parameters, grads\". Outputs: \"parameters\".\n",
    "        parameters = update_parameters(parameters, grads)\n",
    "        \"\"\"\"print(\"grad1: \", grads[\"grad1\"][0][0])\n",
    "        print(\"grad2: \", grads[\"grad2\"][0][0])\n",
    "        print(\"W1: \", parameters[\"W1\"][0][0])\n",
    "        print(\"W2: \", parameters[\"W2\"][0][0])\"\"\"\n",
    "        ### END CODE HERE ###\n",
    "        \n",
    "        # Print the cost every 1000 iterations\n",
    "        if i % 100 == 0:\n",
    "            print (\"Cost after iteration %i: %f\" % (i, cost))\n",
    "\n",
    "    return parameters\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1. 1. 0. 0. 0. 0. 0. 0. 0. 1.]\n"
     ]
    }
   ],
   "source": [
    "zeros = np.zeros((1,10))\n",
    "tmp = np.zeros((1,10))\n",
    "new_train_Y = np.zeros((5000,10))\n",
    "for i in range(0,len(train_Y)):\n",
    "    zeros[0][int(train_Y[i]-1)] = 1\n",
    "    new_train_Y[i] = zeros\n",
    "    zeros = tmp        \n",
    "        \n",
    "print(new_train_Y[1097])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.0\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]\n"
     ]
    }
   ],
   "source": [
    "yNew = np.zeros((5000,10))\n",
    "print(train_Y[1097]%11)\n",
    "for i in range(train_Y.shape[0]):\n",
    "    aux = train_Y[i]%11 - 1\n",
    "    yNew[i,int(aux)] = 1\n",
    "print(yNew[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cost after iteration 0: 6.938379\n",
      "Cost after iteration 100: 1.149115\n",
      "Cost after iteration 200: 0.672859\n",
      "Cost after iteration 300: 0.532930\n",
      "Cost after iteration 400: 0.458103\n",
      "Cost after iteration 500: 0.406893\n",
      "Cost after iteration 600: 0.367831\n",
      "Cost after iteration 700: 0.336155\n",
      "Cost after iteration 800: 0.309446\n",
      "Cost after iteration 900: 0.286418\n",
      "Cost after iteration 1000: 0.266342\n",
      "Cost after iteration 1100: 0.248658\n",
      "Cost after iteration 1200: 0.232917\n",
      "Cost after iteration 1300: 0.218794\n",
      "Cost after iteration 1400: 0.206055\n"
     ]
    }
   ],
   "source": [
    "pesos = nn_model(train_X, yNew, 26)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4.56909730e-04 2.66418957e-01 3.50325947e-03 1.82520437e-07\n",
      " 3.07201797e-04 6.24163599e-05 1.51693036e-04 7.38551597e-01\n",
      " 2.67651115e-03 2.45219918e-04]\n"
     ]
    }
   ],
   "source": [
    "_A2,_cache = forward(train_X,pesos)\n",
    "print(_A2[1097])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[478.   1.   2.   1.   0.   1.   2.   1.   2.   0.]\n",
      " [  2. 442.   5.   1.   1.   2.   2.   1.   0.   0.]\n",
      " [  0.   1. 445.   0.   6.   0.   0.   2.   3.   0.]\n",
      " [  2.   5.   0. 464.   3.   0.   2.   0.   2.   0.]\n",
      " [  0.   0.   8.   0. 432.   2.   0.   1.   0.   0.]\n",
      " [  0.   4.   1.   1.   5. 481.   0.   0.   0.   0.]\n",
      " [  2.   3.   5.   0.   0.   0. 465.   0.   3.   0.]\n",
      " [  3.  10.   2.   1.   2.   0.   0. 447.   0.   0.]\n",
      " [  0.   1.   2.  10.   2.   0.   3.   1. 460.   0.]\n",
      " [ 13.  33.  30.  22.  49.  14.  26.  47.  30. 500.]]\n"
     ]
    }
   ],
   "source": [
    "mat_cross = np.zeros((10,10))\n",
    "prediccion = np.zeros((5000,1))\n",
    "for i in range(0,len(_A2)):\n",
    "    for j in range(0,len(_A2[i])):\n",
    "        if _A2[i][j] >0.5:\n",
    "            prediccion[i][0] = j + 1\n",
    "            \n",
    "for i in range(0,len(prediccion)):\n",
    "    _j = int(train_Y[i]-1) #valor real\n",
    "    _i = int(prediccion[i][0]-1) #valor predicho\n",
    "    mat_cross[_i][_j] += 1\n",
    "    \n",
    "print(mat_cross)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
